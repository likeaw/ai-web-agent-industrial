# æ–‡ä»¶: backend/src/services/BrowserService.py

import json
import os
import subprocess
import tempfile
import time
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
# å¯¼å…¥ Playwright åŒæ­¥ API å’Œ TimeoutError
from playwright.sync_api import sync_playwright, Page, TimeoutError, Error

# å¯¼å…¥ä½ ç°æœ‰çš„æ•°æ®æ¨¡å‹

from backend.src.data_models.decision_engine.decision_models import (
    WebObservation, KeyElement, BoundingBox, ActionFeedback, DecisionAction
)

# æµè§ˆå™¨å·¥å…·å±‚ï¼ˆå•ä¸ªæ“ä½œçš„å¯æ‰©å±•å®ç°ï¼‰
from backend.src.tools.browser import (
    extract_search_results,
    take_screenshot,
    click_nth_match,
    find_link_by_text,
    save_current_page_html,
    download_from_link,
    extract_page_content,
)
from backend.src.tools.browser.llm_html_analyzer import (
    analyze_html_with_llm,
    extract_with_llm_analysis,
)
from backend.src.tools.browser.human_simulator import (
    prepare_page_for_extraction,
    human_like_scroll,
    random_delay,
)
from backend.src.tools.system import resolve_user_path
from backend.src.utils.path_utils import slugify, build_temp_file_path

# å°è¯•å¯¼å…¥OCRå·¥å…·ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨å ä½ç¬¦å‡½æ•°
try:
    from backend.src.tools.image import (
        extract_text_from_image,
        extract_text_from_screenshot,
        analyze_ocr_text_with_llm,
        extract_keywords_from_ocr,
        summarize_ocr_text,
    )
    # æ£€æŸ¥ OCR å·¥å…·çš„å®é™…å¯ç”¨æ€§
    from backend.src.tools.image.ocr_tool import EASYOCR_AVAILABLE, EASYOCR_ERROR
    OCR_AVAILABLE = EASYOCR_AVAILABLE
    OCR_ERROR_DETAILS = EASYOCR_ERROR
except (ImportError, OSError) as e:
    OCR_AVAILABLE = False
    OCR_ERROR_DETAILS = str(e)
    print(f"[BrowserService] OCR tools not available: {e}")
    print("[BrowserService] OCR functionality will be disabled.")
    
    # åˆ›å»ºå ä½ç¬¦å‡½æ•°
    def extract_text_from_screenshot(*args, **kwargs):
        error_msg = "EasyOCR is not available."
        if OCR_ERROR_DETAILS:
            if "DLL" in OCR_ERROR_DETAILS or "c10.dll" in OCR_ERROR_DETAILS:
                error_msg = (
                    "EasyOCR is installed but cannot load due to missing Visual C++ Redistributable.\n"
                    "Please install Visual C++ Redistributable from:\n"
                    "  https://aka.ms/vs/17/release/vc_redist.x64.exe\n"
                    "Or search for 'Visual C++ Redistributable 2015-2022'"
                )
            elif "not installed" in OCR_ERROR_DETAILS.lower() or "ImportError" in str(type(e).__name__):
                error_msg = "EasyOCR is not installed. Please install it with: pip install easyocr"
            else:
                error_msg = f"EasyOCR error: {OCR_ERROR_DETAILS}"
        return {
            "success": False,
            "error": error_msg,
            "text": "",
            "details": []
        }
    
    def analyze_ocr_text_with_llm(*args, **kwargs):
        return {
            "success": False,
            "error": "OCR tools not available",
            "data": {}
        }
else:
    # å¯¼å…¥æˆåŠŸï¼Œä½†éœ€è¦æ£€æŸ¥å®é™…å¯ç”¨æ€§
    try:
        from backend.src.tools.image.ocr_tool import EASYOCR_AVAILABLE, EASYOCR_ERROR
        OCR_AVAILABLE = EASYOCR_AVAILABLE
        OCR_ERROR_DETAILS = EASYOCR_ERROR if not EASYOCR_AVAILABLE else None
    except Exception:
        OCR_AVAILABLE = True  # å¦‚æœæ— æ³•è·å–çŠ¶æ€ï¼Œå‡è®¾å¯ç”¨
        OCR_ERROR_DETAILS = None
class BrowserService:
    def _capture_page_structure(self, task_topic: str = "page_structure") -> Optional[str]:
        """
        æ•è·å½“å‰é¡µé¢çš„ç»“æ„ä¿¡æ¯ï¼Œä¿å­˜ä¸º JSONï¼Œä¾¿äºåç»­å›æº¯é¡µé¢çŠ¶æ€ã€‚
        åªä¿ç•™å…³é”®ä¿¡æ¯å¹¶é™åˆ¶æ•°é‡ï¼Œé˜²æ­¢æ–‡ä»¶è¿‡å¤§ã€‚
        """
        try:
            structure = self.page.evaluate(
                """() => {
                    const limitList = (arr, limit = 100) => arr.slice(0, limit);
                    const cleanText = (t) => (t || "").replace(/\\s+/g, " ").trim();
                    const headings = Array.from(document.querySelectorAll("h1, h2, h3")).map(el => ({
                        tag: el.tagName,
                        text: cleanText(el.innerText || el.textContent || ""),
                    }));
                    const links = limitList(Array.from(document.querySelectorAll("a[href]")).map(el => ({
                        text: cleanText(el.innerText || el.textContent || ""),
                        href: el.getAttribute("href") || "",
                    })), 120);
                    const forms = limitList(Array.from(document.querySelectorAll("form")).map(form => ({
                        action: form.getAttribute("action") || "",
                        method: (form.getAttribute("method") || "GET").toUpperCase(),
                        inputs: limitList(Array.from(form.querySelectorAll("input, textarea, select")).map(input => ({
                            tag: input.tagName,
                            type: input.getAttribute("type") || "text",
                            name: input.getAttribute("name") || "",
                            placeholder: input.getAttribute("placeholder") || "",
                            label: (() => {
                                const id = input.getAttribute("id");
                                if (!id) return "";
                                const label = document.querySelector(`label[for='${id}']`);
                                return label ? cleanText(label.innerText || label.textContent || "") : "";
                            })(),
                        })), 50),
                    })), 30);
                    const sections = limitList(Array.from(document.body.children).map(el => ({
                        tag: el.tagName,
                        id: el.getAttribute("id") || "",
                        class: cleanText(el.getAttribute("class") || ""),
                        text_sample: cleanText((el.innerText || el.textContent || "").slice(0, 200)),
                    })), 30);
                    return {
                        url: window.location.href,
                        title: document.title,
                        headings,
                        links,
                        forms,
                        sections,
                        timestamp: new Date().toISOString(),
                    };
                }"""
            )
            path = build_temp_file_path("other", task_topic or "page_structure", ".json")
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(structure, f, ensure_ascii=False, indent=2)
            print(f"[BrowserService] Page structure captured: {path}")
            return path
        except Exception as e:
            print(f"[BrowserService] Failed to capture page structure: {e}")
            return None

    """
    å·¥ä¸šçº§æµè§ˆå™¨é€‚é…å™¨ (åŸºäº Playwright)ã€‚
    èŒè´£ï¼šæ‰§è¡Œ DecisionActionï¼Œå¹¶è¿”å›æ ‡å‡†åŒ–çš„ WebObservationã€‚
    """

    def __init__(self, headless: bool = True):
        self.playwright = sync_playwright().start()
        # å¯åŠ¨ Chromiumï¼Œå¢åŠ å‚æ•°é¿å…ç¿»è¯‘å¼¹çª—ç­‰å¹²æ‰°ï¼Œå¹¶ä½¿ç”¨ --no-sandbox
        self.browser = self.playwright.chromium.launch(headless=headless, args=['--disable-features=TranslateUI', '--no-sandbox'])
        self.context = self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
        )
        self.page: Page = self.context.new_page()
        self._last_http_status = 200
        self._headless = headless
        self._login_prompt_shown = False

        self.page.on("response", self._handle_response)

    def _handle_response(self, response):
        """æ•è·ä¸»æ–‡æ¡£çš„çŠ¶æ€ç """
        if response.request.resource_type == "document":
            self._last_http_status = response.status

    def close(self):
        self.context.close()
        self.browser.close()
        self.playwright.stop()

    def _detect_login_interface(self) -> Tuple[bool, str]:
        """
        ç»¼åˆæ£€æµ‹ç™»å½•ç•Œé¢ï¼ˆåŒ…æ‹¬ URLã€é¡µé¢å…ƒç´ å’Œå¼¹çª—/æ¨¡æ€æ¡†ï¼‰ã€‚
        
        è¿”å›: (æ˜¯å¦æ£€æµ‹åˆ°ç™»å½•ç•Œé¢, æ£€æµ‹åˆ°çš„ç±»å‹æè¿°)
        """
        try:
            # 1. æ£€æµ‹ URL ä¸­çš„ç™»å½•å…³é”®è¯
            url = (self.page.url or "").lower()
            url_keywords = ["login", "signin", "sign-in", "auth", "authenticate", "signin", "log-in"]
            if any(keyword in url for keyword in url_keywords):
                return True, "URL contains login keywords"
            
            # 2. æ£€æµ‹é¡µé¢ä¸Šçš„å¯†ç è¾“å…¥æ¡†ï¼ˆåŒ…æ‹¬å¼¹çª—ä¸­ï¼‰
            try:
                password_inputs = self.page.locator("input[type='password']")
                if password_inputs.count() > 0:
                    return True, "Password input field detected"
            except Exception:
                pass
            
            # 3. æ£€æµ‹å¼¹çª—/æ¨¡æ€æ¡†ä¸­çš„ç™»å½•ç›¸å…³å†…å®¹
            login_keywords_cn = ["ç™»å½•", "ç™»å…¥", "ç™»é™†", "è´¦å·ç™»å½•", "ç”¨æˆ·ç™»å½•", "ä¼šå‘˜ç™»å½•", "ç«‹å³ç™»å½•"]
            login_keywords_en = ["login", "sign in", "sign-in", "log in", "log-in", "authenticate"]
            all_login_keywords = login_keywords_cn + login_keywords_en
            
            # å¸¸è§çš„å¼¹çª—/æ¨¡æ€æ¡†é€‰æ‹©å™¨
            modal_selectors = [
                "[role='dialog']",
                ".modal",
                ".modal-dialog",
                ".popup",
                ".popup-dialog",
                ".dialog",
                "[class*='modal']",
                "[class*='popup']",
                "[class*='dialog']",
                "[id*='modal']",
                "[id*='popup']",
                "[id*='dialog']",
                "[id*='login']",
                "[class*='login']",
            ]
            
            # æ£€æµ‹å¼¹çª—æ˜¯å¦å¯è§ä¸”åŒ…å«ç™»å½•å…³é”®è¯
            for modal_selector in modal_selectors:
                try:
                    modals = self.page.locator(modal_selector)
                    modal_count = modals.count()
                    
                    for idx in range(min(modal_count, 5)):  # æœ€å¤šæ£€æŸ¥5ä¸ªå¼¹çª—
                        modal = modals.nth(idx)
                        
                        # æ£€æŸ¥å¼¹çª—æ˜¯å¦å¯è§
                        try:
                            if not modal.is_visible(timeout=500):
                                continue
                        except Exception:
                            continue
                        
                        # è·å–å¼¹çª—çš„æ–‡æœ¬å†…å®¹
                        try:
                            modal_text = modal.inner_text().lower()
                        except Exception:
                            continue
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç™»å½•å…³é”®è¯
                        if any(keyword.lower() in modal_text for keyword in all_login_keywords):
                            # è¿›ä¸€æ­¥æ£€æŸ¥å¼¹çª—ä¸­æ˜¯å¦æœ‰å¯†ç è¾“å…¥æ¡†æˆ–ç”¨æˆ·åè¾“å…¥æ¡†
                            has_password_in_modal = False
                            has_username_in_modal = False
                            
                            try:
                                password_in_modal = modal.locator("input[type='password']")
                                if password_in_modal.count() > 0:
                                    has_password_in_modal = True
                            except Exception:
                                pass
                            
                            try:
                                username_selectors = [
                                    "input[type='text']",
                                    "input[type='email']",
                                    "input[name*='user']",
                                    "input[name*='account']",
                                    "input[name*='login']",
                                    "input[placeholder*='user']",
                                    "input[placeholder*='account']",
                                ]
                                for username_sel in username_selectors:
                                    if modal.locator(username_sel).count() > 0:
                                        has_username_in_modal = True
                                        break
                            except Exception:
                                pass
                            
                            if has_password_in_modal or (has_username_in_modal and any(kw in modal_text for kw in ["ç™»å½•", "login", "sign"])):
                                return True, f"Login modal/popup detected (contains login keywords and form fields)"
                            
                            # å³ä½¿æ²¡æœ‰æ˜ç¡®çš„è¡¨å•å­—æ®µï¼Œå¦‚æœåŒ…å«ç™»å½•å…³é”®è¯ä¹Ÿå¯èƒ½éœ€è¦ç™»å½•
                            if any(kw in modal_text for kw in login_keywords_cn + ["login", "sign in"]):
                                return True, f"Login modal/popup detected (contains login keywords)"
                except Exception:
                    continue
            
            # 4. æ£€æµ‹é¡µé¢ä¸»ä½“ä¸­çš„ç™»å½•ç›¸å…³æ–‡æœ¬å’Œè¡¨å•
            try:
                page_text = self.page.inner_text("body").lower()
                if any(keyword.lower() in page_text for keyword in all_login_keywords):
                    # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰ç”¨æˆ·å/å¯†ç è¾“å…¥æ¡†ç»„åˆ
                    try:
                        username_inputs = self.page.locator(
                            "input[type='text'], input[type='email'], input[name*='user'], input[name*='account']"
                        )
                        password_inputs = self.page.locator("input[type='password']")
                        
                        if username_inputs.count() > 0 and password_inputs.count() > 0:
                            return True, "Login form detected on page (username + password inputs)"
                    except Exception:
                        pass
            except Exception:
                pass
            
            return False, ""
        except Exception as e:
            # å¦‚æœæ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œä¿å®ˆå¤„ç†ï¼Œä¸è§¦å‘ç™»å½•ç­‰å¾…
            print(f"[WARN] Error during login detection: {e}")
            return False, ""

    def _maybe_wait_for_manual_login(self):
        """
        æ£€æµ‹æ˜¯å¦å¤„äºç™»å½•é¡µé¢æˆ–ç™»å½•å¼¹çª—ï¼Œå¦‚æœæ˜¯ä¸”ä¸ºæœ‰å¤´æ¨¡å¼ï¼Œåˆ™æç¤ºç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•åæŒ‰å›è½¦ç»§ç»­ã€‚
        æ”¯æŒæ£€æµ‹ URLã€é¡µé¢å…ƒç´ å’Œå¼¹çª—/æ¨¡æ€æ¡†ä¸­çš„ç™»å½•ç•Œé¢ã€‚
        """
        if self._headless or self._login_prompt_shown:
            return

        # ç»™é¡µé¢ä¸€ç‚¹æ—¶é—´åŠ è½½å¼¹çª—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            self.page.wait_for_timeout(1000)  # ç­‰å¾…1ç§’ï¼Œè®©å¼¹çª—æœ‰æ—¶é—´å‡ºç°
        except Exception:
            pass
        
        # ç»¼åˆæ£€æµ‹ç™»å½•ç•Œé¢
        has_login, detection_info = self._detect_login_interface()
        
        if has_login:
            self._login_prompt_shown = True
            print("\n" + "=" * 70)
            print("[HUMAN-ASSIST] ğŸ” ç™»å½•ç•Œé¢æ£€æµ‹")
            print("=" * 70)
            print(f"æ£€æµ‹åˆ°ç™»å½•ç•Œé¢: {detection_info}")
            print("\nè¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ“ä½œï¼ˆå¡«å†™ç”¨æˆ·åã€å¯†ç ç­‰ï¼‰ã€‚")
            print("ç™»å½•å®Œæˆåï¼Œè¯·å›åˆ°æ­¤çª—å£æŒ‰ ENTER é”®ç»§ç»­...")
            print("=" * 70)
            
            try:
                input()
                print("[HUMAN-ASSIST] âœ… å·²æ”¶åˆ°ç¡®è®¤ï¼Œç»§ç»­æ‰§è¡Œä»»åŠ¡...\n")
                # é‡ç½®æ ‡å¿—ï¼Œå…è®¸åç»­å†æ¬¡æ£€æµ‹ï¼ˆä¾‹å¦‚é¡µé¢è·³è½¬åå¯èƒ½å†æ¬¡å‡ºç°ç™»å½•ï¼‰
                self._login_prompt_shown = False
            except EOFError:
                # åœ¨æ— æ³•äº¤äº’çš„ç¯å¢ƒä¸‹ï¼Œç›´æ¥ç»§ç»­ï¼Œä¸é˜»å¡
                print("[HUMAN-ASSIST] âš ï¸  Input not available; continuing without manual login wait.\n")

    def _get_selector(self, args: Dict) -> str:
        """
        [å·¥ä¸šæœ€ç»ˆç‰ˆ] è§£æå®šä½å™¨ã€‚
        æ”¯æŒï¼šXPath, CSS Selector, æ–‡æœ¬å®šä½, å’Œæ–°å¢çš„çˆ¶å­ç»„åˆå®šä½ (container_selector + relative_selector)ã€‚
        """
        # 1. ç²¾ç¡® XPath
        if "xpath" in args and args["xpath"]:
            return f"xpath={args['xpath']}"
            
        # 2. CSS Selector (æ ‡å‡†å®šä½)
        if "selector" in args and args["selector"]:
            return args["selector"]
            
        # 3. çˆ¶å­ç»„åˆå®šä½ (Container + Relative)
        if "container_selector" in args and args["container_selector"]:
            # ä½¿ç”¨ Playwright çš„å¤åˆå®šä½è¯­æ³•: "çˆ¶å®šä½å™¨ >> å­å®šä½å™¨"
            container = args["container_selector"]
            relative = args.get("relative_selector", "") 
            if not relative:
                return container
            return f"{container} >> {relative}" 
            
        # 4. åŸºäºæ–‡æœ¬å†…å®¹çš„æ™ºèƒ½å®šä½ (å…¼å®¹æ—§æ ¼å¼)
        if "text_content" in args and args["text_content"]:
            text = args['text_content']
            if "tag_hint" in args and args["tag_hint"]:
                return f"{args['tag_hint']}:has-text('{text}')"
            else:
                return f"*:has-text('{text}')"
            
        raise ValueError(f"JSON Error: No valid selector provided in args: {args.keys()}")

    def _perform_pre_actions(self, actions: List[Dict[str, Any]], timeout_ms: int) -> None:
        """
        åœ¨æ‰§è¡Œç‰¹å®šå·¥å…·ï¼ˆå¦‚ extract_dataï¼‰å‰ï¼Œæ‰§è¡Œä¸€ç»„ç®€å•çš„é¡µé¢äº¤äº’æ“ä½œã€‚
        æ”¯æŒ click/scroll/waitï¼Œä¾¿äºåœ¨æå–å‰å”¤èµ·æˆ–åŠ è½½æ›´å¤šå†…å®¹ã€‚
        """
        for idx, pre_action in enumerate(actions):
            action_type = (pre_action or {}).get("type")
            if not action_type:
                continue

            try:
                if action_type == "click":
                    selector = self._get_selector(pre_action)
                    self.page.wait_for_selector(selector, state="visible", timeout=timeout_ms)
                    self.page.click(selector, timeout=timeout_ms)
                elif action_type == "scroll":
                    direction = pre_action.get("direction", "down")
                    amount = int(pre_action.get("amount", 800))
                    if direction == "down":
                        self.page.mouse.wheel(0, abs(amount))
                    else:
                        self.page.mouse.wheel(0, -abs(amount))
                elif action_type == "wait":
                    duration = float(pre_action.get("duration", 1))
                    time.sleep(max(0.0, duration))
                else:
                    print(f"[BrowserService] Unknown pre_action '{action_type}' ignored.")
            except Exception as exc:
                print(f"[BrowserService] pre_action #{idx} ({action_type}) failed: {exc}")

    # åœ¨ BrowserService ç±»ä¸­æ–°å¢ä¸€ä¸ªæ–¹æ³•ï¼Œç”¨äºæ‰§è¡Œåçš„éªŒè¯
    def _verify_post_action(self, action: DecisionAction, initial_url: str) -> bool:
        """
        åœ¨æ‰§è¡Œ `click_element` æˆ– `Maps_to` åï¼ŒéªŒè¯æ“ä½œç»“æœã€‚
        """
        # éªŒè¯æ˜¯å¦æˆåŠŸå¯¼èˆª (å³ URL å‘ç”Ÿäº†å˜åŒ–)
        if action.tool_name in ["click_element", "navigate_to"]:
            if self.page.url == initial_url:
                # æ£€æŸ¥é¡µé¢æ˜¯å¦åªæ˜¯å±€éƒ¨åˆ·æ–°ï¼Œæˆ–è€…ç¡®å®æ²¡æœ‰è·³è½¬
                if action.tool_name == "click_element":
                    # åªæœ‰ç‚¹å‡»é“¾æ¥å URL ä»æœªå˜ï¼Œæ‰è®¤ä¸ºæ˜¯å¤±è´¥ (é™¤éé¢„æœŸå°±æ˜¯å±€éƒ¨åˆ·æ–°)
                    print(f"    [VERIFY] Click executed, but URL did not change from {initial_url}. Assuming failure to navigate.")
                    return False
                # å¯¹äº navigate_toï¼ŒURL åº”è¯¥ç­‰äºç›®æ ‡ URLï¼Œå¦‚æœç­‰äºåˆå§‹ URL åˆ™æ˜¯ç½‘ç»œé—®é¢˜
                
        # æˆåŠŸé€šè¿‡éªŒè¯
        return True

    def _extract_interactive_elements(self) -> List[KeyElement]:
        """æ‰«æé¡µé¢ï¼Œæå–å¯¹ AI æœ‰æ„ä¹‰çš„äº¤äº’å…ƒç´ ï¼Œä¿®å¤äº† JS æ³¨å…¥æ—¶çš„è¯­æ³•é”™è¯¯ã€‚"""
        elements = []
        
        js_script = """
        () => {
            const items = [];
            const tags = ['a', 'button', 'input', 'textarea', 'select'];
            document.querySelectorAll(tags.join(',')).forEach((el, index) => {
                const rect = el.getBoundingClientRect();
                const isVisible = rect.width > 0 && rect.height > 0 && window.getComputedStyle(el).visibility !== 'hidden';
                
                if (isVisible) {
                    items.push({
                        element_id: el.id || `gen_id_${index}`,
                        tag_name: el.tagName.toLowerCase(),
                        inner_text: el.innerText.slice(0, 50) || el.value || "", 
                        x_min: rect.left,
                        y_min: rect.top,
                        x_max: rect.right,
                        y_max: rect.bottom,
                        xpath: ""
                    });
                }
            });
            return items;
        }
        """
        
        try:
            raw_data = self.page.evaluate(js_script)
            
            for item in raw_data:
                xpath = f"//{item['tag_name']}[@id='{item['element_id']}']" if "gen_id" not in item['element_id'] else f"//{item['tag_name']}"

                elements.append(KeyElement(
                    element_id=item['element_id'],
                    tag_name=item['tag_name'],
                    xpath=xpath, 
                    inner_text=item['inner_text'].strip(),
                    is_visible=True,
                    is_clickable=True,
                    bbox=BoundingBox(
                        x_min=item['x_min'],
                        y_min=item['y_min'],
                        x_max=item['x_max'],
                        y_max=item['y_max']
                    ),
                    purpose_hint=None
                ))
        except Exception as e:
            print(f"[WARN] Error extracting elements: {e}")
            
        return elements
        
    def get_element_attribute(self, selector: str, attribute_name: str) -> str:
        """
        æ ¹æ® CSS Selector å®šä½å…ƒç´ å¹¶æå–æŒ‡å®šçš„å±æ€§å€¼ã€‚
        :param selector: å…ƒç´ çš„ Playwright/CSS Selectorã€‚
        :param attribute_name: è¦æå–çš„å±æ€§åï¼Œå¦‚ 'href', 'value'ã€‚
        :return: å±æ€§å€¼ï¼Œå¦‚æœå…ƒç´ ä¸å­˜åœ¨æˆ–å±æ€§ä¸å­˜åœ¨åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
        """
        try:
            # ä½¿ç”¨ page.locator æ¥è·å–å…ƒç´ ï¼Œå¹¶ç­‰å¾…å®ƒå¤„äºå¯è§çŠ¶æ€
            locator = self.page.locator(selector)
            # ç­‰å¾…å…ƒç´ å¯è§ï¼Œæœ€å¤šç­‰å¾… 10 ç§’
            locator.wait_for(state="visible", timeout=10000) 
            
            # ä½¿ç”¨ get_attribute æå–å±æ€§å€¼
            attribute_value = locator.get_attribute(attribute_name)
            
            return attribute_value if attribute_value is not None else ""
        
        except TimeoutError:
            print(f"[BrowserService] Error: Element not visible or attribute not found for selector: {selector}")
            return ""
        except Error as e:
            print(f"[BrowserService] Playwright Error during get_element_attribute: {e}")
            return ""

    def _launch_notepad(self, action: DecisionAction, feedback: ActionFeedback):
        """
        å¯åŠ¨ Windows è®°äº‹æœ¬ï¼Œå¹¶å¯é€‰åœ°å†™å…¥åˆå§‹å†…å®¹ã€‚
        """
        file_path = action.tool_args.get("file_path")
        initial_content = action.tool_args.get("initial_content")

        if file_path:
            target_path = os.path.abspath(file_path)
            os.makedirs(os.path.dirname(target_path), exist_ok=True)
        else:
            fd, temp_path = tempfile.mkstemp(prefix="agent_note_", suffix=".txt")
            os.close(fd)
            target_path = temp_path

        if initial_content:
            with open(target_path, "w", encoding="utf-8") as f:
                f.write(initial_content)

        try:
            subprocess.Popen(["notepad.exe", target_path], creationflags=subprocess.DETACHED_PROCESS)
            feedback.status = "SUCCESS"
            feedback.message = f"Notepad opened for file: {target_path}"
        except Exception as exc:
            feedback.status = "FAILED"
            feedback.error_code = "NOTEPAD_LAUNCH_ERROR"
            feedback.message = f"Failed to open Notepad: {exc}"
            raise

    def execute_action(self, action: DecisionAction) -> WebObservation:
        """
        æ ¸å¿ƒå…¥å£ï¼šæ‰§è¡ŒåŠ¨ä½œ -> ç­‰å¾…é¡µé¢ç¨³å®š -> æå–è§‚æµ‹æ•°æ®
        """
        start_time = time.time()
        feedback = ActionFeedback(status="SUCCESS", error_code="0", message="Action executed.")
        initial_url = self.page.url
        timeout_ms = action.execution_timeout_seconds * 1000

        try:
            # 1. æ‰§è¡Œå…·ä½“åŠ¨ä½œ
            if action.tool_name == "navigate_to":
                url = action.tool_args.get("url")
                if not url:
                    raise ValueError("Missing 'url' in tool_args")
                self.page.goto(url, wait_until="load", timeout=timeout_ms)
                # å¯¼èˆªåæ£€æŸ¥æ˜¯å¦å‘½ä¸­ç™»å½•é¡µé¢
                self._maybe_wait_for_manual_login()
                # æ•è·é¡µé¢ç»“æ„ï¼Œä¾¿äºå›é€€å’Œå®¡è®¡
                self._capture_page_structure(task_topic=action.tool_args.get("task_topic", "page_structure"))
            
            elif action.tool_name == "type_text":
                selector = self._get_selector(action.tool_args)
                text = action.tool_args.get("text", "")
                submit_key = action.tool_args.get("submit_key") # <-- è·å–æäº¤é”®å‚æ•°

                # 1. å¡«å……æ–‡æœ¬ï¼šç­‰å¾…å…ƒç´ å­˜åœ¨äº DOM ä¸­ï¼Œå¹¶å¼ºåˆ¶å¡«å……ã€‚
                self.page.wait_for_selector(selector, state="attached", timeout=timeout_ms)
                self.page.fill(selector, text, timeout=timeout_ms, force=True)
                
                # 2. ã€äººç±»æ¨¡æ‹Ÿæ“ä½œã€‘å¦‚æœæŒ‡å®šäº†æäº¤é”®ï¼Œåˆ™æŒ‰ä¸‹å®ƒæ¥æäº¤è¡¨å•
                if submit_key:
                    # ä½¿ç”¨ page.press æ¨¡æ‹Ÿé”®ç›˜æ“ä½œï¼Œæ›´é²æ£’
                    self.page.press(selector, submit_key)
                    print(f"[BrowserService] Human-like simulation: Pressed '{submit_key}' on {selector} to submit.")
                
            elif action.tool_name == "get_element_attribute":
                selector = self._get_selector(action.tool_args)
                attribute_name = action.tool_args.get("attribute_name", "href")
                
                print(f"    -> Extracting attribute '{attribute_name}' from target: {selector}")
                
                # è°ƒç”¨æ–°æ·»åŠ çš„æ–¹æ³•
                extracted_value = self.get_element_attribute(selector, attribute_name)
                
                if extracted_value:
                    # å°†æå–åˆ°çš„å€¼å­˜å…¥ feedback.messageï¼Œä½œä¸º SUCCESS æ—¶çš„ç»“æœ
                    feedback.message = f"Attribute '{attribute_name}' extracted: {extracted_value}"
                    feedback.status = "SUCCESS"
                else:
                    feedback.status = "FAILED"
                    feedback.error_code = "ATTRIBUTE_NOT_FOUND"
                    feedback.message = f"Failed to extract attribute '{attribute_name}' from {selector}. Target not found or attribute missing."
                    raise Error(feedback.message)
                
            elif action.tool_name == "extract_data":
                # å‚æ•°æå–
                selector = action.tool_args.get("selector")
                attribute = action.tool_args.get("attribute", "text")  # é»˜è®¤æå–å…ƒç´ çš„æ–‡æœ¬
                limit = action.tool_args.get("limit")  # å¯ä»¥æ˜¯ Noneï¼ˆæå–å…¨éƒ¨ï¼‰
                pre_actions = action.tool_args.get("pre_actions", [])
                # ã€é‡è¦ã€‘é»˜è®¤ä½¿ç”¨OCRæ¨¡å¼æå–å†…å®¹
                extract_mode = action.tool_args.get("mode", "ocr")  # é»˜è®¤ä½¿ç”¨OCRæ¨¡å¼
                use_ocr = action.tool_args.get("use_ocr", True)  # é»˜è®¤ä½¿ç”¨OCRï¼ˆé™¤éæ˜ç¡®è®¾ç½®ä¸ºFalseï¼‰
                use_llm = action.tool_args.get("use_llm", True)  # é»˜è®¤ä½¿ç”¨ LLM åˆ†æOCRç»“æœ
                extraction_instruction = action.tool_args.get("extraction_instruction", "")  # LLM æå–æŒ‡ä»¤
                prepare_page = action.tool_args.get("prepare_page", True)  # æ˜¯å¦å‡†å¤‡é¡µé¢ï¼ˆå±•å¼€æŠ˜å ã€è§¦å‘æ‡’åŠ è½½ç­‰ï¼‰

                if not selector:
                    # å›é€€åˆ°é€šç”¨é€‰æ‹©å™¨è§£æé€»è¾‘ï¼ˆæ”¯æŒ xpath / text_content ç­‰ï¼‰
                    try:
                        selector = self._get_selector(action.tool_args)
                    except Exception:
                        selector = None

                # ã€å…³é”®å¢å¼ºã€‘åœ¨æå–å‰å…¨é¢å‡†å¤‡é¡µé¢ï¼Œæ¨¡æ‹Ÿäººç±»æ“ä½œ
                if prepare_page:
                    print("[BrowserService] Preparing page for extraction (expanding collapsible content, triggering lazy load)...")
                    try:
                        prepare_page_for_extraction(self.page)
                    except Exception as e:
                        print(f"[BrowserService] Page preparation warning: {e}")

                if isinstance(pre_actions, list) and pre_actions:
                    self._perform_pre_actions(pre_actions, timeout_ms)

                results = []
                extraction_done = False
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æå–åšå®¢æ­£æ–‡å†…å®¹
                extract_blog_mode = action.tool_args.get("extract_blog_content", False)
                content_type = action.tool_args.get("content_type", "blog_content")  # é»˜è®¤æå–åšå®¢å†…å®¹
                
                # ã€é‡è¦ã€‘é»˜è®¤ä½¿ç”¨OCRæ–¹å¼æå–å†…å®¹ï¼ˆå¦‚æœOCRå¯ç”¨ï¼‰
                if OCR_AVAILABLE and (use_ocr or extract_mode == "ocr" or extract_mode == "comprehensive"):
                    print("[BrowserService] Using OCR-based extraction (screenshot + OCR)...")
                    
                    # 1. å…ˆæˆªå›¾
                    task_topic = action.tool_args.get("task_topic", "extract_content")
                    screenshot_path = take_screenshot(
                        page=self.page,
                        task_topic=task_topic,
                        filename=None,
                        full_page=True,
                        custom_path=None,
                    )
                    
                    # 2. ä½¿ç”¨OCRæå–æ–‡å­—
                    print(f"[BrowserService] Extracting text from screenshot: {screenshot_path}")
                    ocr_result = extract_text_from_screenshot(
                        screenshot_path=screenshot_path,
                        languages=["ch_sim", "en"],
                        detail=0,
                    )
                    
                    if not ocr_result.get("success"):
                        print(f"[BrowserService] OCR extraction failed: {ocr_result.get('error')}")
                        print("[BrowserService] Falling back to HTML-based extraction...")
                        use_ocr = False
                    else:
                        ocr_text = ocr_result.get("text", "")
                        if not ocr_text or len(ocr_text.strip()) < 10:
                            print("[BrowserService] OCR extracted empty or very short text")
                            print("[BrowserService] Falling back to HTML-based extraction...")
                            use_ocr = False
                        else:
                            # 3. ä½¿ç”¨LLMåˆ†æOCRç»“æœï¼ˆæå–ç»“æ„åŒ–ä¿¡æ¯ï¼‰
                            if use_llm:
                                print("[BrowserService] Analyzing OCR text with LLM...")
                                
                                if extract_blog_mode or content_type == "blog_content":
                                    # æå–åšå®¢å†…å®¹
                                    if not extraction_instruction:
                                        extraction_instruction = (
                                            "è¯·ä»ä»¥ä¸ŠOCRè¯†åˆ«çš„æ–‡æœ¬ä¸­æå–åšå®¢/æ–‡ç« å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š"
                                            "1. æ–‡ç« æ ‡é¢˜ï¼ˆtitleï¼‰- å¦‚æœæœ‰çš„è¯"
                                            "2. æ­£æ–‡å†…å®¹ï¼ˆcontentï¼‰- å®Œæ•´çš„æ–‡ç« æ­£æ–‡æ–‡æœ¬ï¼Œè¿™æ˜¯æœ€é‡è¦çš„"
                                            "3. ä½œè€…ä¿¡æ¯ï¼ˆauthorï¼Œå¦‚æœå­˜åœ¨ï¼‰"
                                            "4. å‘å¸ƒæ—¶é—´ï¼ˆpublish_timeï¼Œå¦‚æœå­˜åœ¨ï¼‰"
                                            "å¿½ç•¥å¯¼èˆªæ ã€é¡µè„šã€å¹¿å‘Šã€è¯„è®ºåŒºç­‰æ— å…³å†…å®¹ï¼Œåªæå–æ–‡ç« çš„æ ¸å¿ƒæ­£æ–‡å†…å®¹ã€‚"
                                            "è¿”å›JSONæ ¼å¼ï¼š{\"title\": \"æ ‡é¢˜\", \"content\": \"æ­£æ–‡å†…å®¹\", \"author\": \"ä½œè€…\", \"publish_time\": \"æ—¶é—´\"}"
                                        )
                                    
                                    llm_result = analyze_ocr_text_with_llm(ocr_text, extraction_instruction)
                                    
                                    if llm_result.get("success") and "data" in llm_result:
                                        blog_data = llm_result["data"]
                                        if "content" not in blog_data or not blog_data.get("content"):
                                            blog_data["content"] = ocr_text
                                        results = [blog_data]
                                    else:
                                        print("[BrowserService] LLM analysis failed, using raw OCR text")
                                        results = [{
                                            "title": "",
                                            "content": ocr_text,
                                            "author": "",
                                            "publish_time": "",
                                            "url": self.page.url
                                        }]
                                else:
                                    # æå–é“¾æ¥æˆ–å…¶ä»–å†…å®¹
                                    if not extraction_instruction:
                                        extraction_instruction = (
                                            "è¯·ä»ä»¥ä¸ŠOCRè¯†åˆ«çš„æ–‡æœ¬ä¸­æå–æ‰€æœ‰å¯ä»¥è·³è½¬çš„URLé“¾æ¥ï¼Œ"
                                            "æ ¼å¼ä¸ºæ ‡é¢˜å’ŒURLçš„å¯¹åº”å…³ç³»ã€‚"
                                            "å¿½ç•¥å¯¼èˆªæ ã€é¡µè„šã€å¹¿å‘Šç­‰æ— å…³é“¾æ¥ã€‚"
                                        )
                                    
                                    llm_result = analyze_ocr_text_with_llm(ocr_text, extraction_instruction)
                                    
                                    if llm_result.get("success") and "data" in llm_result:
                                        data = llm_result["data"]
                                        if "items" in data:
                                            results = data["items"]
                                        elif "links" in data:
                                            results = data["links"]
                                        else:
                                            results = [{"text": ocr_text, "url": self.page.url}]
                                    else:
                                        results = [{"text": ocr_text, "url": self.page.url}]
                            else:
                                # ä¸ä½¿ç”¨LLMï¼Œç›´æ¥è¿”å›OCRæ–‡æœ¬
                                if extract_blog_mode or content_type == "blog_content":
                                    results = [{
                                        "title": "",
                                        "content": ocr_text,
                                        "author": "",
                                        "publish_time": "",
                                        "url": self.page.url
                                    }]
                                else:
                                    results = [{"text": ocr_text, "url": self.page.url}]
                            
                            extraction_done = True
                
                else:
                    # OCRä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨HTMLæå–
                    if not OCR_AVAILABLE:
                        print("[BrowserService] OCR not available, using HTML-based extraction...")
                        if OCR_ERROR_DETAILS:
                            if "DLL" in OCR_ERROR_DETAILS or "c10.dll" in OCR_ERROR_DETAILS:
                                print("[BrowserService] Note: EasyOCR is installed but cannot load.")
                                print("[BrowserService] Install Visual C++ Redistributable to enable OCR:")
                                print("[BrowserService]   https://aka.ms/vs/17/release/vc_redist.x64.exe")
                    use_ocr = False
                
                # å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚æœOCRä¸å¯ç”¨æˆ–ç”¨æˆ·æ˜ç¡®ç¦ç”¨ï¼Œæˆ–OCRé˜¶æ®µæœªäº§ç”Ÿç»“æœï¼‰
                if (not use_ocr or extract_mode not in ["ocr"]) and not extraction_done:
                    if extract_mode == "comprehensive" or (extract_mode == "llm" or use_llm):
                        # ç»¼åˆç­–ç•¥ï¼šå…ˆå°è¯• LLM åˆ†æï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°é«˜çº§æå–
                        print("[BrowserService] Using comprehensive extraction strategy (LLM + Advanced)...")
                        
                        # 1. å…ˆå°è¯• LLM åˆ†æ
                        html_content = self.page.content()
                        
                        if extraction_instruction:
                            extraction_instruction_final = extraction_instruction
                        else:
                            # æ ¹æ®å†…å®¹ç±»å‹ç”Ÿæˆä¸åŒçš„é»˜è®¤æŒ‡ä»¤
                            if extract_blog_mode or content_type == "blog_content":
                                extraction_instruction_final = (
                                    "æå–å½“å‰é¡µé¢çš„åšå®¢/æ–‡ç« æ­£æ–‡å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š"
                                    "1. æ–‡ç« æ ‡é¢˜ï¼ˆtitleï¼‰"
                                    "2. æ­£æ–‡å†…å®¹ï¼ˆcontentï¼‰- å®Œæ•´çš„æ–‡ç« æ­£æ–‡æ–‡æœ¬"
                                    "3. ä½œè€…ä¿¡æ¯ï¼ˆauthorï¼Œå¦‚æœå­˜åœ¨ï¼‰"
                                    "4. å‘å¸ƒæ—¶é—´ï¼ˆpublish_timeï¼Œå¦‚æœå­˜åœ¨ï¼‰"
                                    "å¿½ç•¥å¯¼èˆªæ ã€é¡µè„šã€å¹¿å‘Šã€è¯„è®ºåŒºç­‰æ— å…³å†…å®¹ï¼Œåªæå–æ–‡ç« çš„æ ¸å¿ƒæ­£æ–‡å†…å®¹ã€‚"
                                    "è¿”å›æ ¼å¼åº”ä¸ºJSONï¼ŒåŒ…å«titleã€contentã€authorã€publish_timeå­—æ®µã€‚"
                                )
                            elif content_type == "both":
                                extraction_instruction_final = (
                                    "æå–é¡µé¢ä¸­çš„ä»¥ä¸‹ä¿¡æ¯ï¼š"
                                    "1. æ‰€æœ‰å¯ä»¥è·³è½¬çš„ URL é“¾æ¥ï¼ˆæ ¼å¼ä¸ºæ ‡é¢˜å’Œ URL çš„å¯¹åº”å…³ç³»ï¼‰"
                                    "2. å¦‚æœå½“å‰é¡µé¢æ˜¯åšå®¢/æ–‡ç« é¡µé¢ï¼Œæå–æ–‡ç« æ­£æ–‡å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€ä½œè€…ã€å‘å¸ƒæ—¶é—´ï¼‰"
                                    "å¿½ç•¥å¯¼èˆªæ ã€é¡µè„šã€å¹¿å‘Šç­‰æ— å…³å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨ä¸»è¦å†…å®¹åŒºåŸŸã€‚"
                                )
                            else:
                                extraction_instruction_final = (
                                    "æå–é¡µé¢ä¸­æ‰€æœ‰å¯ä»¥è·³è½¬çš„ URL é“¾æ¥ï¼Œæ ¼å¼ä¸ºæ ‡é¢˜å’Œ URL çš„å¯¹åº”å…³ç³»ã€‚"
                                    "å¿½ç•¥å¯¼èˆªæ ã€é¡µè„šã€å¹¿å‘Šç­‰æ— å…³é“¾æ¥ï¼Œé‡ç‚¹å…³æ³¨ä¸»è¦å†…å®¹åŒºåŸŸçš„é“¾æ¥ã€‚"
                                    "åŒ…æ‹¬æœç´¢ç»“æœã€æ–‡ç« é“¾æ¥ã€äº§å“é“¾æ¥ç­‰æ‰€æœ‰å¯ç‚¹å‡»çš„é“¾æ¥ã€‚"
                                )
                        
                        llm_result = analyze_html_with_llm(
                            html_content,
                            extraction_instruction_final,
                            max_html_length=50000
                        )
                        
                        if llm_result.get("success") and "data" in llm_result:
                            data = llm_result["data"]
                            if "items" in data and data["items"]:
                                results = data["items"]
                            elif "links" in data and data["links"]:
                                results = data["links"]
                            elif "title" in data or "content" in data:
                                # LLMè¿”å›äº†åšå®¢å†…å®¹æ ¼å¼
                                results = [data]  # å°†åšå®¢å†…å®¹ä½œä¸ºå•ä¸ªç»“æœé¡¹
                        
                        # 2. å¦‚æœ LLM æå–å¤±è´¥æˆ–ç»“æœä¸ºç©ºï¼Œå›é€€åˆ°é«˜çº§æå–
                        if not results:
                            print("[BrowserService] LLM extraction returned no results, falling back to advanced extraction...")
                            
                            if extract_blog_mode or content_type == "blog_content":
                                # æå–åšå®¢æ­£æ–‡å†…å®¹
                                page_content = extract_page_content(
                                    page=self.page,
                                    current_url=self.page.url,
                                    mode="blog_content",
                                    selector=selector,
                                    include_html=False,
                                )
                                if "data" in page_content:
                                    results = [page_content["data"]]  # å°†åšå®¢å†…å®¹ä½œä¸ºå•ä¸ªç»“æœé¡¹
                            else:
                                # æå–é“¾æ¥
                                page_content = extract_page_content(
                                    page=self.page,
                                    current_url=self.page.url,
                                    mode="links",
                                    selector=selector,
                                    limit=limit,
                                    include_html=False,
                                )
                                if "data" in page_content and "links" in page_content["data"]:
                                    results = page_content["data"]["links"]
                    
                    elif extract_mode == "llm":
                        # ä»…ä½¿ç”¨ LLM åˆ†æ
                        print("[BrowserService] Using LLM-based HTML analysis for extraction...")
                        html_content = self.page.content()
                        
                        if extraction_instruction:
                            llm_result = analyze_html_with_llm(
                                html_content,
                                extraction_instruction,
                                max_html_length=50000
                            )
                            if llm_result.get("success") and "data" in llm_result:
                                data = llm_result["data"]
                                if "items" in data:
                                    results = data["items"]
                                elif "links" in data:
                                    results = data["links"]
                                elif "title" in data or "content" in data:
                                    # LLMè¿”å›äº†åšå®¢å†…å®¹æ ¼å¼
                                    results = [data]
                        else:
                            if extract_blog_mode or content_type == "blog_content":
                                extraction_instruction_default = (
                                    "æå–å½“å‰é¡µé¢çš„åšå®¢/æ–‡ç« æ­£æ–‡å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€ä½œè€…ã€å‘å¸ƒæ—¶é—´ã€‚"
                                    "è¿”å›JSONæ ¼å¼ï¼ŒåŒ…å«titleã€contentã€authorã€publish_timeå­—æ®µã€‚"
                                )
                                llm_result = analyze_html_with_llm(
                                    html_content,
                                    extraction_instruction_default,
                                    max_html_length=50000
                                )
                                if llm_result.get("success") and "data" in llm_result:
                                    results = [llm_result["data"]]
                            else:
                                results = extract_with_llm_analysis(
                                    html_content,
                                    task_description=action.tool_args.get("task_description", "æå–é¡µé¢ä¸­æ‰€æœ‰å¯è·³è½¬çš„ URL é“¾æ¥"),
                                    max_html_length=50000
                                )
                    
                    elif extract_mode == "advanced":
                        # ä½¿ç”¨é«˜çº§æå–å·¥å…·
                        print("[BrowserService] Using advanced page content extraction...")
                        
                        if extract_blog_mode or content_type == "blog_content":
                            # æå–åšå®¢æ­£æ–‡å†…å®¹
                            page_content = extract_page_content(
                                page=self.page,
                                current_url=self.page.url,
                                mode="blog_content",
                                selector=selector,
                                include_html=False,
                            )
                            if "data" in page_content:
                                results = [page_content["data"]]
                        else:
                            # æå–é“¾æ¥
                            page_content = extract_page_content(
                                page=self.page,
                                current_url=self.page.url,
                                mode="links",
                                selector=selector,
                                limit=limit,
                                include_html=False,
                            )
                            if "data" in page_content and "links" in page_content["data"]:
                                results = page_content["data"]["links"]
                    
                    else:
                        # ä½¿ç”¨åŸæœ‰çš„ç®€å•æå–é€»è¾‘
                        if limit is None:
                            limit = 10  # é»˜è®¤é™åˆ¶
                        
                        if extract_blog_mode or content_type == "blog_content":
                            # ç®€å•æ¨¡å¼ä¸‹ä¹Ÿæ”¯æŒæå–åšå®¢å†…å®¹
                            page_content = extract_page_content(
                                page=self.page,
                                current_url=self.page.url,
                                mode="blog_content",
                                selector=selector,
                                include_html=False,
                            )
                            if "data" in page_content:
                                results = [page_content["data"]]
                        else:
                            results = extract_search_results(
                                page=self.page,
                                current_url=self.page.url,
                                selector=selector,
                                attribute=attribute,
                                limit=limit,
                            )

                if results:
                    feedback.status = "SUCCESS"
                    # åˆ¤æ–­ç»“æœç±»å‹ï¼šå¦‚æœæ˜¯åšå®¢å†…å®¹ï¼ˆåŒ…å«titleæˆ–contentå­—æ®µï¼‰ï¼Œä½¿ç”¨blog_contentç±»å‹
                    if results and isinstance(results[0], dict) and ("title" in results[0] or "content" in results[0]):
                        payload = {
                            "result_type": "blog_content",
                            "items": results,
                        }
                        # ç¡®ä¿contentå­—æ®µå­˜åœ¨ä¸”ä¸ä¸ºç©º
                        for item in results:
                            if isinstance(item, dict):
                                # ç¡®ä¿contentå­—æ®µå­˜åœ¨
                                if "content" not in item or not item.get("content"):
                                    # å¦‚æœcontentä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
                                    if "text" in item and item["text"]:
                                        item["content"] = item["text"]
                                    elif "ocr_text" in item and item["ocr_text"]:
                                        item["content"] = item["ocr_text"]
                                    else:
                                        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè‡³å°‘ç¡®ä¿contentå­—æ®µå­˜åœ¨
                                        item["content"] = item.get("content", "")
                                # ç¡®ä¿contentæ˜¯å­—ç¬¦ä¸²ç±»å‹
                                if item.get("content") and not isinstance(item["content"], str):
                                    item["content"] = str(item["content"])
                    else:
                        payload = {
                            "result_type": "link_list",
                            "items": results,
                        }
                    summary = json.dumps(payload, ensure_ascii=False)
                    print(f"[BrowserService] extract_data -> Extracted {len(results)} items (type: {payload['result_type']})")
                    # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                    if results and isinstance(results[0], dict) and "content" in results[0]:
                        content_preview = str(results[0].get("content", ""))[:200]
                        print(f"[BrowserService] Content preview (first 200 chars): {content_preview}...")
                    feedback.message = summary
                else:
                    feedback.status = "FAILED"
                    feedback.error_code = "NO_DATA_EXTRACTED"
                    feedback.message = "extract_data: no items extracted from page."
                    print("[BrowserService] extract_data -> NO DATA EXTRACTED")

            elif action.tool_name == "take_screenshot":
                # task_topic ä¸»è¦ç”¨äºç”Ÿæˆæœ‰è¯­ä¹‰çš„æ–‡ä»¶å
                task_topic = action.tool_args.get("task_topic", "web_page")
                filename = action.tool_args.get("filename")
                full_page = bool(action.tool_args.get("full_page", True))
                output_path_arg = action.tool_args.get("output_path")
                output_dir_arg = action.tool_args.get("output_dir")
                custom_output_path: Optional[str] = None

                try:
                    if output_path_arg:
                        custom_output_path = resolve_user_path(output_path_arg)
                    elif output_dir_arg:
                        resolved_dir = resolve_user_path(output_dir_arg)
                        os.makedirs(resolved_dir, exist_ok=True)
                        name = filename
                        if not name:
                            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                            name = f"{slugify(task_topic)}_{ts}.png"
                        custom_output_path = os.path.join(resolved_dir, name)
                except ValueError as exc:
                    raise ValueError(f"Invalid screenshot output path: {exc}") from exc

                screenshot_path = take_screenshot(
                    page=self.page,
                    task_topic=task_topic,
                    filename=filename,
                    full_page=full_page,
                    custom_path=custom_output_path,
                )

                feedback.status = "SUCCESS"
                feedback.message = f"Screenshot saved to: {screenshot_path}"

            elif action.tool_name == "download_page":
                task_topic = action.tool_args.get("task_topic", "web_page")
                path = save_current_page_html(self.page, task_topic=task_topic)
                feedback.status = "SUCCESS"
                feedback.message = f"Page HTML saved to: {path}"

            elif action.tool_name == "download_link":
                task_topic = action.tool_args.get("task_topic", "download")
                url = action.tool_args.get("url")
                selector = None
                if not url and any(k in action.tool_args for k in ("selector", "xpath", "text_content", "container_selector")):
                    selector = self._get_selector(action.tool_args)

                path = download_from_link(
                    page=self.page,
                    task_topic=task_topic,
                    url=url,
                    selector=selector,
                )
                feedback.status = "SUCCESS"
                feedback.message = f"Downloaded content saved to: {path}"

            elif action.tool_name == "click_nth":
                selector = self._get_selector(action.tool_args)
                index = int(action.tool_args.get("index", 0))
                timeout_ms = int(action.tool_args.get("timeout_ms", timeout_ms))

                print(f"    -> Clicking element #{index} for selector: {selector}")
                click_nth_match(
                    page=self.page,
                    selector=selector,
                    index=index,
                    timeout_ms=timeout_ms,
                )

            elif action.tool_name == "find_link_by_text":
                keyword = action.tool_args.get("keyword")
                limit = int(action.tool_args.get("limit", 5))

                if not keyword:
                    raise ValueError("find_link_by_text requires 'keyword' in tool_args.")

                matches = find_link_by_text(
                    page=self.page,
                    keyword=keyword,
                    limit=limit,
                )

                feedback.status = "SUCCESS"
                feedback.message = f"Found {len(matches)} links: {matches}"

            elif action.tool_name == "click_element":
                selector = self._get_selector(action.tool_args)
                print(f"    -> Clicking target: {selector}")
                
                timeout_ms = action.execution_timeout_seconds * 1000

                # ğŸš€ å·¥ä¸šçº§ä¿®å¤ï¼šä½¿ç”¨ Playwright çš„ expect_navigation æ¥å¤„ç†ç‚¹å‡»å¯¼è‡´çš„é¡µé¢è·³è½¬ã€‚
                # è¿™æ ·å¯ä»¥å¯é åœ°ç­‰å¾…è·³è½¬å®Œæˆï¼Œæˆ–åœ¨è¶…æ—¶æ—¶æŠ›å‡º TimeoutErrorã€‚
                
                # 1. ç¡®ä¿å…ƒç´ å¯è§
                self.page.wait_for_selector(selector, state="visible", timeout=timeout_ms)
                
                # 2. é¢„æœŸå¯¼èˆªå‘ç”Ÿå¹¶æ‰§è¡Œç‚¹å‡»
                # è¿™ä¸€æ­¥ä¼šç­‰å¾… URL å˜åŒ–æˆ–é¡µé¢åŠ è½½å®Œæˆã€‚
                # å¦‚æœç‚¹å‡»ä¸å¯¼è‡´å¯¼èˆªï¼Œexpect_navigation ä¼šè¶…æ—¶ï¼Œæ‰€ä»¥ç”¨ try-except å¤„ç†
                try:
                    with self.page.expect_navigation(timeout=timeout_ms):
                        self.page.click(selector, timeout=timeout_ms)
                except TimeoutError:
                    # ç‚¹å‡»å¯èƒ½ä¸å¯¼è‡´å¯¼èˆªï¼ˆå¦‚æŒ‰é’®è§¦å‘ AJAXï¼‰ï¼Œç›´æ¥ç‚¹å‡»å³å¯
                    self.page.click(selector, timeout=timeout_ms)
                
                # ç‚¹å‡»åå¯èƒ½è·³è½¬åˆ°ç™»å½•é¡µï¼Œåšä¸€æ¬¡æ£€æµ‹
                self._maybe_wait_for_manual_login()

            elif action.tool_name == "open_notepad":
                self._launch_notepad(action, feedback)

            elif action.tool_name == "scroll":
                direction = action.tool_args.get("direction", "down")
                scroll_amount = action.tool_args.get("amount", "window.innerHeight")
                
                js_scroll = f"window.scrollBy(0, {scroll_amount})" if direction == "down" else f"window.scrollBy(0, -{scroll_amount})"
                self.page.evaluate(js_scroll)
            
            elif action.tool_name == "wait":
                duration = action.tool_args.get("duration", 2)
                time.sleep(duration)

            elif action.tool_name == "extract_text_from_image":
                # OCR æ–‡å­—è¯†åˆ«å·¥å…·
                image_path = action.tool_args.get("image_path")
                languages = action.tool_args.get("languages", ["ch_sim", "en"])
                detail = int(action.tool_args.get("detail", 0))
                
                if not image_path:
                    raise ValueError("extract_text_from_image requires 'image_path' in tool_args")
                
                # è§£æè·¯å¾„
                try:
                    resolved_path = resolve_user_path(image_path)
                except ValueError:
                    resolved_path = os.path.abspath(image_path)
                
                result = extract_text_from_image(
                    image_path=resolved_path,
                    languages=languages if isinstance(languages, list) else ["ch_sim", "en"],
                    detail=detail,
                )
                
                if result.get("success"):
                    feedback.status = "SUCCESS"
                    payload = {
                        "result_type": "ocr_text",
                        "text": result.get("text", ""),
                        "details": result.get("details", []),
                    }
                    summary = json.dumps(payload, ensure_ascii=False)
                    feedback.message = summary
                    print(f"[BrowserService] OCR extracted {len(result.get('text', ''))} characters from image")
                else:
                    feedback.status = "FAILED"
                    feedback.error_code = "OCR_EXTRACTION_FAILED"
                    feedback.message = f"OCR extraction failed: {result.get('error', 'Unknown error')}"
                    raise Error(feedback.message)

            elif action.tool_name == "analyze_ocr_text":
                # OCR æ–‡æœ¬åˆ†æå·¥å…·ï¼ˆä½¿ç”¨ LLM åˆ†æ OCR ç»“æœï¼‰
                ocr_text = action.tool_args.get("ocr_text")
                analysis_instruction = action.tool_args.get("analysis_instruction")
                analysis_type = action.tool_args.get("analysis_type", "custom")  # custom, keywords, summary
                
                if not ocr_text:
                    raise ValueError("analyze_ocr_text requires 'ocr_text' in tool_args")
                
                if analysis_type == "keywords":
                    max_keywords = int(action.tool_args.get("max_keywords", 10))
                    language = action.tool_args.get("language", "zh")
                    result = extract_keywords_from_ocr(ocr_text, max_keywords, language)
                elif analysis_type == "summary":
                    max_length = int(action.tool_args.get("max_length", 200))
                    result = summarize_ocr_text(ocr_text, max_length)
                else:
                    # è‡ªå®šä¹‰åˆ†æ
                    if not analysis_instruction:
                        raise ValueError("analyze_ocr_text with analysis_type='custom' requires 'analysis_instruction'")
                    result = analyze_ocr_text_with_llm(ocr_text, analysis_instruction)
                
                if result.get("success"):
                    feedback.status = "SUCCESS"
                    payload = {
                        "result_type": "ocr_analysis",
                        "analysis_type": analysis_type,
                        "data": result.get("data", {}),
                    }
                    summary = json.dumps(payload, ensure_ascii=False)
                    feedback.message = summary
                    print(f"[BrowserService] OCR text analysis completed (type: {analysis_type})")
                else:
                    feedback.status = "FAILED"
                    feedback.error_code = "OCR_ANALYSIS_FAILED"
                    feedback.message = f"OCR text analysis failed: {result.get('error', 'Unknown error')}"
                    raise Error(feedback.message)

            elif action.tool_name == "extract_text_from_screenshot":
                # ä»æˆªå›¾æå–æ–‡å­—ï¼ˆOCRï¼‰
                screenshot_path = action.tool_args.get("screenshot_path")
                languages = action.tool_args.get("languages", ["ch_sim", "en"])
                detail = int(action.tool_args.get("detail", 0))
                analyze_with_llm = bool(action.tool_args.get("analyze_with_llm", False))
                analysis_instruction = action.tool_args.get("analysis_instruction", "")
                
                if not screenshot_path:
                    raise ValueError("extract_text_from_screenshot requires 'screenshot_path' in tool_args")
                
                # è§£æè·¯å¾„
                try:
                    resolved_path = resolve_user_path(screenshot_path)
                except ValueError:
                    resolved_path = os.path.abspath(screenshot_path)
                
                # æ‰§è¡Œ OCR
                ocr_result = extract_text_from_screenshot(
                    screenshot_path=resolved_path,
                    languages=languages if isinstance(languages, list) else ["ch_sim", "en"],
                    detail=detail,
                )
                
                if not ocr_result.get("success"):
                    feedback.status = "FAILED"
                    feedback.error_code = "OCR_EXTRACTION_FAILED"
                    feedback.message = f"OCR extraction failed: {ocr_result.get('error', 'Unknown error')}"
                    raise Error(feedback.message)
                
                ocr_text = ocr_result.get("text", "")
                
                # å¦‚æœéœ€è¦ä½¿ç”¨ LLM åˆ†æ
                if analyze_with_llm:
                    if not analysis_instruction:
                        analysis_instruction = "æå–æ–‡æœ¬ä¸­çš„å…³é”®è¯å’Œä¸»è¦å†…å®¹æ‘˜è¦"
                    
                    llm_result = analyze_ocr_text_with_llm(ocr_text, analysis_instruction)
                    
                    if llm_result.get("success"):
                        feedback.status = "SUCCESS"
                        payload = {
                            "result_type": "ocr_with_analysis",
                            "ocr_text": ocr_text,
                            "analysis": llm_result.get("data", {}),
                        }
                        summary = json.dumps(payload, ensure_ascii=False)
                        feedback.message = summary
                        print(f"[BrowserService] OCR + LLM analysis completed")
                    else:
                        # OCR æˆåŠŸä½† LLM åˆ†æå¤±è´¥ï¼Œè‡³å°‘è¿”å› OCR ç»“æœ
                        feedback.status = "SUCCESS"
                        payload = {
                            "result_type": "ocr_text",
                            "text": ocr_text,
                            "analysis_error": llm_result.get("error", "Unknown error"),
                        }
                        summary = json.dumps(payload, ensure_ascii=False)
                        feedback.message = summary
                        print(f"[BrowserService] OCR completed, but LLM analysis failed")
                else:
                    # åªè¿”å› OCR ç»“æœ
                    feedback.status = "SUCCESS"
                    payload = {
                        "result_type": "ocr_text",
                        "text": ocr_text,
                        "details": ocr_result.get("details", []),
                    }
                    summary = json.dumps(payload, ensure_ascii=False)
                    feedback.message = summary
                    print(f"[BrowserService] OCR extracted {len(ocr_text)} characters from screenshot")

            else:
                raise ValueError(f"Unsupported tool: {action.tool_name}")

            # ç­‰å¾…ç½‘ç»œç©ºé—²
            try:
                self.page.wait_for_load_state("networkidle", timeout=3000)
            except TimeoutError:
                pass 
            
            # æ“ä½œå®Œæˆåï¼Œæ£€æµ‹æ˜¯å¦å‡ºç°äº†ç™»å½•ç•Œé¢ï¼ˆåŒ…æ‹¬å¼¹çª—ï¼‰
            # è¿™å¯ä»¥åœ¨é¡µé¢åŠ è½½æˆ– AJAX æ“ä½œå®Œæˆåæ•è·çªç„¶å‡ºç°çš„ç™»å½•å¼¹çª—
            self._maybe_wait_for_manual_login() 

        except Error as e:
            # æ•è·æ‰€æœ‰ Playwright é”™è¯¯
            feedback.status = "FAILED"
            feedback.error_code = "PLAYWRIGHT_ERROR"
            feedback.message = str(e)
            print(f"[BrowserService] Action Failed: {e}")
            
        except Exception as e:
            # æ•è·å…¶ä»– Python é”™è¯¯
            feedback.status = "FAILED"
            feedback.error_code = "EXECUTION_ERROR"
            feedback.message = str(e)
            print(f"[BrowserService] Action Failed: {e}")

        # 2. æ„é€  WebObservation
        end_time = time.time()
        load_time_ms = int((end_time - start_time) * 1000)
        
        return WebObservation(
            observation_timestamp_utc=str(time.time()),
            current_url=self.page.url,
            http_status_code=self._last_http_status,
            page_load_time_ms=load_time_ms if feedback.status == "SUCCESS" else 0,
            is_authenticated=False, 
            key_elements=self._extract_interactive_elements(), 
            screenshot_available=False, 
            last_action_feedback=feedback,
            memory_context="Browser state captured."
        )